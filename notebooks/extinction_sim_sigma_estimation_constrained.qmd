---
title: "Similarity-aware vs Random Extinction Selection (MDS + fear ratings)"
format:
  html:
    toc: true
execute:
  warning: false
  message: false
params:
  data_path: "data/coors_rates_2dims.csv"
  id_col: "...1"
  x_cols: ["D1", "D2"]
  fear_col: "fear_mean"
  T: 40              # number of extinction trials (stimuli selected)
  eta: 0.15          # learning rate (0..1)
  sigma_scale: 0.5   # sigma = sigma_scale * median(pairwise distance)
  kernel: "gaussian"        # "gaussian" or "exponential"
  estimate_sigma: true      # estimate sigma from baseline fear smoothness (LOO kernel regression)
  sigma_grid_scales: [0.1, 0.2, 0.3, 0.5, 0.8, 1.0, 1.5, 2.0]  # candidates: × median pairwise distance
  n_random: 500      # number of random schedules to average over
  seed: 1
  run_hierarchy: true      # include fear-only fixed-order baselines
  run_constrained: true   # include similarity-aware constrained by ascending fear cap
  hierarchy_orders: ["ascending", "descending"]  # fixed order by baseline fear
---

```{r}

library(tidyverse)
library(here)

set.seed(params$seed)

# ---- Load data ----
dat <- read_csv(here(params$data_path), show_col_types = FALSE) %>%
  rename(id = all_of(params$id_col)) %>%
  mutate(
    id = as.character(id),
    fear0 = .data[[params$fear_col]]
  )


stopifnot(all(params$x_cols %in% names(dat)))
stopifnot("fear0" %in% names(dat))

X <- as.matrix(dat[, params$x_cols])
fear0 <- dat$fear0
N <- nrow(dat)

# ---- Distance matrix + generalization kernel ----
D <- as.matrix(dist(X))
medD <- median(D[upper.tri(D)])

kernel_weights <- function(D, sigma, kernel = c("gaussian", "exponential")) {
  kernel <- match.arg(kernel)
  if (kernel == "gaussian") {
    exp(-(D^2) / (2 * sigma^2))
  } else {
    exp(-D / sigma)
  }
}

loo_kernel_r2 <- function(y, D, sigma, kernel) {
  y <- as.numeric(y)
  ybar <- mean(y)
  sst <- sum((y - ybar)^2)

  W <- kernel_weights(D, sigma, kernel)
  diag(W) <- 0  # leave-one-out
  denom <- rowSums(W)
  yhat <- ifelse(denom > 0, (W %*% y) / denom, ybar)

  sse <- sum((y - yhat)^2)
  as.numeric(1 - sse / sst)
}

if (isTRUE(params$estimate_sigma)) {
  sigma_grid <- medD * unlist(params$sigma_grid_scales)

  sigma_fit <- tibble(
    sigma = sigma_grid,
    scale = sigma_grid / medD,
    r2_loo = purrr::map_dbl(sigma_grid, ~ loo_kernel_r2(fear0, D, .x, params$kernel))
  ) %>%
    arrange(desc(r2_loo))

  sigma <- sigma_fit$sigma[1]
  sigma_scale_used <- sigma_fit$scale[1]
  sigma_r2 <- sigma_fit$r2_loo[1]
} else {
  sigma <- params$sigma_scale * medD
  sigma_scale_used <- params$sigma_scale
  sigma_r2 <- NA_real_
  sigma_fit <- tibble(sigma = sigma, scale = sigma_scale_used, r2_loo = sigma_r2)
}

K <- kernel_weights(D, sigma, params$kernel)  # K[i,j] in (0,1]; K[i,i] = 1

# Fixed fear-only orders based on baseline fear
order_asc <- order(fear0, decreasing = FALSE)
order_desc <- order(fear0, decreasing = TRUE)
```


```{r}
# ---- Optional: bandwidth selection diagnostics ----
if (isTRUE(params$estimate_sigma)) {
  ggplot(sigma_fit, aes(x = scale, y = r2_loo)) +
    geom_line() +
    geom_point() +
    labs(
      x = "sigma (× median pairwise distance)",
      y = "LOO R² predicting baseline fear",
      title = "Bandwidth selection for fear smoothness"
    ) +
    theme_minimal()
}
```

```{r}
# ---- One-step update: multiplicative reduction generalized by kernel row ----
update_fear <- function(fear, s_idx, eta, K) {
  fear_new <- fear * (1 - eta * K[s_idx, ])
  pmax(fear_new, 0)
}

# ---- Policy: similarity-aware greedy (maximize predicted global fear reduction) ----
# Gain(i) = sum_j fear_j * K[i,j]
choose_similarity_aware <- function(fear, available, K) {
  gains <- rowSums(K[available, , drop = FALSE] * matrix(fear, nrow = length(available), ncol = length(fear), byrow = TRUE))
  available[which.max(gains)]
}

# ---- Policy: similarity-aware with tolerability constraint (ascending fear cap) ----
# At trial tt, only allow stimuli with baseline fear <= cap implied by ascending hierarchy:
# cap(tt) = baseline fear of the tt-th item in ascending order.
choose_similarity_constrained <- function(fear, available, K, fear0, order_asc, tt) {
  idx_cap <- order_asc[pmin(tt, length(order_asc))]
  cap <- fear0[idx_cap]
  eligible <- intersect(available, which(fear0 <= cap))

  # Fallback: ensure at least the cap item is eligible
  if (length(eligible) == 0) eligible <- intersect(available, idx_cap)

  choose_similarity_aware(fear, eligible, K)
}


# ---- Simulate one schedule ----
# Policies:
# - "similarity": greedy selection using MDS similarity and current fear
# - "random": random order
# - "ascending": fixed order by baseline fear (low -> high)
# - "descending": fixed order by baseline fear (high -> low)
simulate_schedule <- function(policy = c("similarity", "similarity_constrained", "random", "ascending", "descending"),
                              fear0, K, T, eta, order_asc, order_desc, seed = NULL) {
  policy <- match.arg(policy)
  if (!is.null(seed)) set.seed(seed)

  fear <- fear0
  available <- seq_along(fear0)
  chosen <- integer(0)

  out <- tibble(
    t = 0:T,
    mean_fear = NA_real_
  )
  out$mean_fear[1] <- mean(fear)

  for (tt in 1:T) {
    if (length(available) == 0) {
      # if T > N, allow repeats by resetting availability
      available <- seq_along(fear0)
    }

    s <- if (policy == "random") {
      sample(available, 1)
    } else if (policy == "similarity") {
      choose_similarity_aware(fear, available, K)
    } else if (policy == "similarity_constrained") {
      choose_similarity_constrained(fear, available, K, fear0, order_asc, tt)
    } else if (policy == "ascending") {
      order_asc[order_asc %in% available][1]
    } else { # descending
      order_desc[order_desc %in% available][1]
    }

    fear <- update_fear(fear, s, eta, K)

    chosen <- c(chosen, s)
    available <- setdiff(available, s)

    out$mean_fear[tt + 1] <- mean(fear)
  }

  list(curve = out, chosen = chosen)
}

# ---- Run similarity-aware (deterministic) ----
sim_sim <- simulate_schedule(
  "similarity", fear0, K, params$T, params$eta,
  order_asc = order_asc, order_desc = order_desc,
  seed = params$seed
)
curve_sim <- sim_sim$curve %>% mutate(policy = "Similarity-aware", run = 1)

# ---- Run similarity-aware (constrained by ascending fear cap) ----
sim_sim_con <- NULL
curve_sim_con <- NULL
if (isTRUE(params$run_constrained)) {
  sim_sim_con <- simulate_schedule(
    "similarity_constrained", fear0, K, params$T, params$eta,
    order_asc = order_asc, order_desc = order_desc,
    seed = params$seed
  )
  curve_sim_con <- sim_sim_con$curve %>% mutate(policy = "Similarity-aware (constrained)", run = 1)
}


# ---- Run random many times ----
curves_rand <- map_dfr(seq_len(params$n_random), function(r) {
  sim <- simulate_schedule(
    "random", fear0, K, params$T, params$eta,
    order_asc = order_asc, order_desc = order_desc,
    seed = params$seed + r
  )
  sim$curve %>% mutate(policy = "Random", run = r)
})

# Summarize random curves (band across runs)
curve_rand_sum <- curves_rand %>%
  group_by(t) %>%
  summarise(
    avg_mean_fear = mean(mean_fear, na.rm = TRUE),
    lo = quantile(mean_fear, 0.05, na.rm = TRUE),
    hi = quantile(mean_fear, 0.95, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(policy = "Random")

# ---- Optional: fear-only fixed-order baselines ----
curve_hier <- NULL
hier_sims <- list()
if (isTRUE(params$run_hierarchy)) {
  orders <- params$hierarchy_orders
  hier_sims <- rlang::set_names(vector("list", length(orders)), orders)

  curve_hier <- purrr::map_dfr(orders, function(o) {
    sim <- simulate_schedule(
      o, fear0, K, params$T, params$eta,
      order_asc = order_asc, order_desc = order_desc,
      seed = params$seed
    )
    hier_sims[[o]] <<- sim
    sim$curve %>% mutate(policy = paste0("Fear-only (", o, ")"), run = 1)
  })
}

# ---- Plot learning curves ----
line_df <- bind_rows(
  curve_sim,
  curve_sim_con,
  curve_hier
)

p <- ggplot() +
  geom_ribbon(
    data = curve_rand_sum,
    aes(x = t, ymin = lo, ymax = hi),
    alpha = 0.2
  ) +
  geom_line(
    data = curve_rand_sum,
    aes(x = t, y = avg_mean_fear, color = policy, linetype = policy),
    linewidth = 1
  ) +
  geom_line(
    data = line_df,
    aes(x = t, y = mean_fear, color = policy, linetype = policy),
    linewidth = 1
  ) +
  labs(
    x = "Extinction trial (selected stimulus)",
    y = "Mean fear (simulated)",
    title = "Extinction simulation with similarity-based generalization",
    subtitle = paste0(
      "T=", params$T, ", eta=", params$eta,
      ", kernel=", params$kernel,
      ", sigma=", round(sigma, 3),
      " (", round(sigma_scale_used, 2), "× median distance)"
    ),
    color = NULL,
    linetype = NULL
  ) +
  theme_minimal()

p
```

```{r}
# ---- Simple summary metrics ----
auc_vec <- function(y) sum((y[-1] + y[-length(y)]) / 2)

t50_vec <- function(t, y) {
  thr <- 0.5 * y[t == 0][1]
  hit <- which(y <= thr)
  if (length(hit) == 0) NA_integer_ else t[min(hit)]
}

# Similarity-aware metrics
metrics_sim <- tibble(
  policy = "Similarity-aware",
  auc = auc_vec(curve_sim$mean_fear),
  t50 = t50_vec(curve_sim$t, curve_sim$mean_fear),
  final_mean_fear = curve_sim$mean_fear[curve_sim$t == params$T]
)

# Constrained similarity-aware metrics
metrics_sim_con <- NULL
if (!is.null(curve_sim_con)) {
  metrics_sim_con <- tibble(
    policy = "Similarity-aware (constrained)",
    auc = auc_vec(curve_sim_con$mean_fear),
    t50 = t50_vec(curve_sim_con$t, curve_sim_con$mean_fear),
    final_mean_fear = curve_sim_con$mean_fear[curve_sim_con$t == params$T]
  )
}

# Random metrics: per-run then summary
metrics_rand_runs <- curves_rand %>%
  group_by(run) %>%
  summarise(
    auc = auc_vec(mean_fear),
    t50 = t50_vec(t, mean_fear),
    final_mean_fear = mean_fear[t == params$T][1],
    .groups = "drop"
  )

metrics_rand <- metrics_rand_runs %>%
  summarise(
    policy = "Random",
    avg_auc = mean(auc),
    auc_lo = quantile(auc, 0.05),
    auc_hi = quantile(auc, 0.95),
    avg_t50 = median(t50, na.rm = TRUE),
    t50_lo = quantile(t50, 0.05, na.rm = TRUE),
    t50_hi = quantile(t50, 0.95, na.rm = TRUE),
    avg_final_mean_fear = mean(final_mean_fear),
    final_lo = quantile(final_mean_fear, 0.05),
    final_hi = quantile(final_mean_fear, 0.95),
    .groups = "drop"
  )

# Optional hierarchy metrics (fixed order)
metrics_hier <- NULL
if (!is.null(curve_hier) && nrow(curve_hier) > 0) {
  metrics_hier <- curve_hier %>%
    group_by(policy) %>%
    summarise(
      auc = auc_vec(mean_fear),
      t50 = t50_vec(t, mean_fear),
      final_mean_fear = mean_fear[t == params$T][1],
      .groups = "drop"
    )
}

improvement_vs_random <- tibble(
  metric = c("AUC (percent)", "Final mean fear (percent)", "T50 (trials)"),
  value = c(
    100 * (metrics_rand$avg_auc - metrics_sim$auc) / metrics_rand$avg_auc,
    100 * (metrics_rand$avg_final_mean_fear - metrics_sim$final_mean_fear) / metrics_rand$avg_final_mean_fear,
    metrics_rand$avg_t50 - metrics_sim$t50
  )
)

list(
  params = list(
    T = params$T,
    eta = params$eta,
    kernel = params$kernel,
    sigma = sigma,
    sigma_scale_used = sigma_scale_used,
    sigma_r2_loo = sigma_r2
  ),
  similarity_aware = metrics_sim,
  similarity_constrained = metrics_sim_con,
  random_summary = metrics_rand,
  hierarchy = metrics_hier,
  improvement_vs_random = improvement_vs_random,
  improvement_vs_ascending = {
    if (!is.null(metrics_sim_con) && !is.null(metrics_hier) && any(metrics_hier$policy == "Fear-only (ascending)")) {
      asc <- metrics_hier %>% filter(policy == "Fear-only (ascending)") %>% slice(1)
      tibble(
        metric = c("AUC (percent)", "Final mean fear (percent)"),
        value = c(
          100 * (asc$auc - metrics_sim_con$auc) / asc$auc,
          100 * (asc$final_mean_fear - metrics_sim_con$final_mean_fear) / asc$final_mean_fear
        )
      )
    } else {
      tibble(metric = character(0), value = numeric(0))
    }
  }
)
```

```{r}
# ---- Optional: visualize which stimuli were selected on the MDS map ----
# Build a long table of selected items for each policy we want to display.
sel_df <- tibble(
  id = dat$id,
  x = dat[[params$x_cols[1]]],
  y = dat[[params$x_cols[2]]]
)

sel_points <- bind_rows(
  tibble(
    id = dat$id[sim_sim$chosen],
    chosen_order = seq_along(sim_sim$chosen),
    policy = "Similarity-aware"
  ),
  {
    if (!is.null(sim_sim_con) && !is.null(sim_sim_con$chosen)) {
      tibble(
        id = dat$id[sim_sim_con$chosen],
        chosen_order = seq_along(sim_sim_con$chosen),
        policy = "Similarity-aware (constrained)"
      )
    } else {
      tibble(id = character(0), chosen_order = integer(0), policy = character(0))
    }
  },

  {
    if (!is.null(hier_sims) && "ascending" %in% names(hier_sims) && !is.null(hier_sims[["ascending"]])) {
      tibble(
        id = dat$id[hier_sims[["ascending"]]$chosen],
        chosen_order = seq_along(hier_sims[["ascending"]]$chosen),
        policy = "Fear-only (ascending)"
      )
    } else {
      tibble(id = character(0), chosen_order = integer(0), policy = character(0))
    }
  },
  {
    if (!is.null(hier_sims) && "descending" %in% names(hier_sims) && !is.null(hier_sims[["descending"]])) {
      tibble(
        id = dat$id[hier_sims[["descending"]]$chosen],
        chosen_order = seq_along(hier_sims[["descending"]]$chosen),
        policy = "Fear-only (descending)"
      )
    } else {
      tibble(id = character(0), chosen_order = integer(0), policy = character(0))
    }
  }
) %>%
  left_join(sel_df, by = "id") %>%
  filter(!is.na(x) & !is.na(y))

ggplot(sel_df, aes(x = x, y = y)) +
  geom_point(alpha = 0.5) +
  geom_point(
    data = sel_points,
    aes(color = policy),
    size = 2
  ) +
  geom_text(
    data = sel_points,
    aes(label = chosen_order, color = policy),
    nudge_y = 0.03,
    size = 3,
    show.legend = FALSE
  ) +
  labs(
    title = "Selected stimuli across policies (order annotated)",
    x = params$x_cols[1], y = params$x_cols[2],
    color = NULL
  ) +
  theme_minimal()

```
